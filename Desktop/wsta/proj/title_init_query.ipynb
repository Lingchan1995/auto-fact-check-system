{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"title_init_query.ipynb","version":"0.3.2","provenance":[],"collapsed_sections":[]},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.6.8"},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"}},"cells":[{"cell_type":"markdown","metadata":{"id":"HCpZvOGSG5qL","colab_type":"text"},"source":["# Querying the index and getting the candidates docs\n","written by Yige Wen\n","\n","----"]},{"cell_type":"code","metadata":{"id":"Ev4mPNgPG5qO","colab_type":"code","colab":{}},"source":["from whoosh.qparser import QueryParser\n","from whoosh import scoring\n","import time\n","\n","from whoosh.index import open_dir\n","ix = open_dir('title_index_analyzer')"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"o5rOGV0WG5qY","colab_type":"code","colab":{},"outputId":"8704192b-1571-498b-db41-f7e9e3c6df9d"},"source":["from whoosh import analysis\n","analyzer1=analysis.KeywordAnalyzer(lowercase=True)\n","title = \"Robert_J._O'Neill_-LRB-U.S._Navy_SEAL-RRB-\"\n","\n","\n","def delete_bracket(title):\n","    result = []\n","    tokens = ' '.join(title.split(\"_\"))\n","#     print([t.text for t in analyzer(tokens)])\n","    tokens = [t.text for t in analyzer1(tokens)]\n","    for t in tokens:\n","        if t[:5] != '-lrb-' and t[-5:] != '-rrb-':\n","            result.append(t)\n","    return ' '.join(result)\n","\n","print(delete_bracket(title))\n","\n","def pre_process(title):\n","    tokens = title.replace(\"_\", ' ')\n","    tokens = tokens.replace(\"-\", ' ')\n","    tokens = tokens.replace(\"COLON\", '')\n","    tokens = tokens.split()\n","    stack = [tokens[0]]\n","    \n","    if stack[0] == 'LRB':\n","        tokens = ' '.join(tokens)\n","        tokens = tokens.replace(\"LRB\", '')\n","        tokens = tokens.replace(\"RRB\", '')\n","        return tokens.split()\n","    \n","    for i in range(1, len(tokens)):\n","        head = stack[-1]\n","        if head == 'LRB':\n","            if tokens[i] == 'RRB':\n","                stack.pop()\n","            elif tokens[i] == 'LRB':\n","                stack.append(tokens[i])\n","            continue\n","        stack.append(tokens[i])\n","    return stack\n","\n","print(pre_process(title))"],"execution_count":0,"outputs":[{"output_type":"stream","text":["robert j. o'neill navy\n","['Robert', 'J.', \"O'Neill\"]\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"WomMHHzSG5qn","colab_type":"code","colab":{},"outputId":"3843a28d-8f94-42b6-c682-fbc54eda27a3"},"source":["def get_rid_of_s(entity):\n","    ent = entity[:]\n","    ent = ent.split(' ')\n","    if ent[-1] == \"'\" or ent[-1] == \"'s\":\n","        ent.pop()\n","    return ' '.join(ent)\n","\n","get_rid_of_s(\"Carey Hayes '\")"],"execution_count":0,"outputs":[{"output_type":"execute_result","data":{"text/plain":["'Carey Hayes'"]},"metadata":{"tags":[]},"execution_count":3}]},{"cell_type":"code","metadata":{"id":"8bPLNj6rG5qy","colab_type":"code","colab":{},"outputId":"db4a24d6-0486-4607-ff34-f6b844b08210"},"source":["import json\n","\n","with open('NER-CF-test-unlabelled.json','r') as f:\n","    data = json.load(f)\n","\n","# with open('NER-CF-test-unlabelled.json','r') as f:\n","#     data = json.load(f)\n","    \n","print(len(data))\n","    \n","for k,v in data.items():\n","    for ent in v['entities']:\n","        x = get_rid_of_s(ent)\n","        if not x in v['entities']:\n","            v['entities'].append(x)\n","        v['entities'] = list(set(v['entities']))\n","        \n","    temp = []\n","    for ent in v['entities']:\n","        ent = ent.split(' ')\n","        if len(ent)>1 or ent[0].isalpha():\n","            temp.append(' '.join(ent))\n","    v['entities'] = temp\n","print(data['63631'])\n","# print(data['204443'])\n"],"execution_count":0,"outputs":[{"output_type":"stream","text":["14997\n","{'claim': 'In the End was released in 1700 .', 'entities': ['In the End']}\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"Ou5-nizfG5q8","colab_type":"code","colab":{}},"source":["from collections import Counter\n","\n","def filter_title(title, claim):\n","    title_counts = Counter(title)\n","    claim_counts = Counter(claim)\n","    for k,v in title_counts.items():\n","        if v > claim_counts[k]:\n","            return False\n","    return True"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"rHZK9ewCG5rD","colab_type":"code","colab":{}},"source":["from whoosh.qparser import QueryParser\n","\n","from whoosh import analysis\n","analyzer2=analysis.StandardAnalyzer(minsize=1, stoplist=[])\n","\n","import time\n","start = time.clock()\n","\n","doc_results = {}\n","with ix.searcher() as searcher1:\n","    i = 1\n","    for k,v in data.items():\n","#         if i == 2:\n","#             break\n","#         i += 1\n","        doc_result = {}\n","        evidence = []\n","#         set_claim = set([t.text for t in analyzer2(v['claim'])])\n","        claim = [t.text for t in analyzer2(v['claim'])]\n","        entities = v['entities']\n","        titles = []\n","        for q in entities:\n","            query = QueryParser(\"content\", ix.schema).parse(q)\n","            result = searcher1.search(query, limit=20)\n","            ##\n","            for hit in result:\n","                real_title = [t.text for t in analyzer2(' '.join(pre_process(hit['title'])))]\n","#                 print(real_title)\n","#                 print(set_claim)\n","#                 if set(real_title).issubset(set_claim):\n","#                     titles.append(hit['title'])\n","                if filter_title(real_title,claim):\n","                    titles.append(hit['title'])\n","            ##\n","#             titles += [hit['title'] for hit in result]\n","            \n","        titles = list(set(titles))\n","        for t in titles:\n","            evidence.append([t, 0])\n","        \n","#         doc_result['claim'] = ' '.join(v['claim'])\n","        doc_result['label'] = 'SUPPORTS'\n","        doc_result['evidence'] = evidence\n","        doc_results[k] = doc_result\n","\n","with open(\"result_limit_20-NER-CF-test-unlabelled.json\",\"w\") as w:\n","    json.dump(doc_results, w, indent=2, separators=(', ', ': '))\n","        \n","# with open(\"result_limit_20-NER-CF-test-unlabelled.json\",\"w\") as w:\n","#     json.dump(doc_results, w, indent=2, separators=(', ', ': '))"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"0I-JGndkG5rK","colab_type":"code","colab":{},"outputId":"227132b4-d3f3-4259-a4fb-d86143043436"},"source":["analyzer2=analysis.StandardAnalyzer(minsize=1)\n","print([t.text for t in analyzer2( \"See.SZA.Run\")])"],"execution_count":0,"outputs":[{"output_type":"stream","text":["['see.sza.run']\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"xAsD3E_lG5rV","colab_type":"code","colab":{},"outputId":"72e8b068-1488-46de-fc73-e032d832de53"},"source":["with open('result_limit_20-NER-CF-test-unlabelled.json','r') as f:\n","    data = json.load(f)\n","print(len(data))\n","\n","for k,v in data.items():\n","    v['label'] = 'SUPPORTS'\n","\n","with open('testoutput.json','w') as w:\n","    json.dump(data, w, indent=2, separators=(', ', ': '))"],"execution_count":0,"outputs":[{"output_type":"stream","text":["14997\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"7iJISXshG5re","colab_type":"code","colab":{}},"source":["inputJson = 'devset.json'\n","with open(inputJson,'r') as f:\n","    data = json.load(f)\n","print(len(data))\n","\n","out = {}\n","for k,v in data.items():\n","    if v['label'][0] != 'N':\n","        out[k] = v\n","print(len(out))\n","\n","with open('devset_supp_refu.json','w') as w:\n","    json.dump(out, w, indent=2, separators=(', ', ': '))"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"86FSQK9tG5rh","colab_type":"code","colab":{},"outputId":"a432f3c2-edc4-4455-8d29-fa843e153b35"},"source":["from whoosh.qparser import QueryParser\n","from whoosh import scoring\n","import time\n","\n","start = time.clock()\n","\n","entities = [\n","      \"See SZA Run\"\n","    ]\n","# entities = list(set([\" \".join(pre_process(e)) for e in entities]))\n","\n","with ix.searcher() as searcher1:\n","    print(time.clock() - start)\n","    for q in entities:\n","        parser = QueryParser(\"content\", ix.schema)\n","        query = parser.parse(q)\n","        print(query)\n","        results = searcher1.search(query)\n","        for hit in results:\n","            print(hit['title'], hit['wiki'])\n","        print(time.clock() - start)\n","        \n","elapsed = (time.clock() - start)\n","print(\"Time used:\",elapsed)"],"execution_count":0,"outputs":[{"output_type":"stream","text":["1.639811\n","(content:see AND content:sza AND content:run)\n","1.6494109999999997\n","Time used: 1.7380630000000004\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"1wHsJjBLG5rm","colab_type":"code","colab":{}},"source":["from whoosh.qparser import QueryParser\n","\n","from whoosh import analysis\n","analyzer2=analysis.StandardAnalyzer(minsize=1)\n","\n","doc_results = {}\n","with ix.searcher() as searcher1:\n","\n","    k = '59356'\n","    v =  data[k]\n","    \n","    doc_result = {}\n","    evidence = []\n","    set_claim = set([t.text for t in analyzer2(v['claim'])])\n","    entities = v['entities']\n","    titles = []\n","    for q in entities:\n","        query = QueryParser(\"content\", ix.schema).parse(q)\n","        result = searcher1.search(query)\n","        ##\n","        for hit in result:\n","            real_title = [t.text for t in analyzer2(' '.join(pre_process(hit['title'])))]\n","            print(real_title)\n","            print(set_claim)\n","            print(set(real_title).issubset(set_claim))\n","            if set(real_title).issubset(set_claim):\n","                titles.append(hit['title'])\n","        ##\n","#             titles += [hit['title'] for hit in result]\n","\n","    titles = list(set(titles))\n","    for t in titles:\n","        evidence.append([t, 0])\n","        \n","#         doc_result['claim'] = ' '.join(v['claim'])\n","        doc_result['label'] = 'SUPPORTS'\n","        doc_result['evidence'] = evidence\n","        doc_results[k] = doc_result\n","        \n","print(doc_results[k])"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"wGA5LRQsG5rq","colab_type":"code","colab":{}},"source":["from allennlp.predictors.predictor import Predictor\n","predictor = Predictor.from_path(\"https://s3-us-west-2.amazonaws.com/allennlp/models/coref-model-2018.02.05.tar.gz\")\n","predictor.predict(\n","  document=\"Paul Allen was born on January 21, 1953, in Seattle, Washington, to Kenneth Sam Allen and Edna Faye Allen. Allen attended Lakeside School, a private school in Seattle, where he befriended Bill Gates, two years younger, with whom he shared an enthusiasm for computers. Paul and Bill used a teletype terminal at their high school, Lakeside, to develop their programming skills on several time-sharing computer systems.\"\n",")"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"JZKlVF8NG5rt","colab_type":"code","colab":{}},"source":[""],"execution_count":0,"outputs":[]}]}